{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kAVXf8Owdj_"
   },
   "source": [
    "# Multimodal Classification Training\n",
    "\n",
    "This notebook creates the Multimodal Network Architecture and trains it for grasp testset1. After training the network weights will be stored in the folder `./dataset/grasp_testset1_logs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9PQVYgswdkG"
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "`Python 3.5.4` is used for development and following packages are required to run the code provided in the notebook:\n",
    "\n",
    "`pip install googledrivedownloader`<br>\n",
    "`pip install matplotlib`<br>\n",
    "`pip install tensorflow-gpu`<br>\n",
    "`pip install keras`<br>\n",
    "`pip install numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN0aShvGw1pt",
    "outputId": "be7b5555-28a1-426b-83d8-a9aa76130d78"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Onu-rrTryUqx",
    "outputId": "aefb2778-7e10-46e3-8aae-b6a9bed129fc"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.15.0\n",
    "#!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Tkd2IbswwdkJ"
   },
   "outputs": [],
   "source": [
    "import os, csv, time, shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# path=\"/content/drive/MyDrive/Deep-Multi-Sensory-Object-Categorization\"\n",
    "path = \"/home/alex/Deep-Multi-Sensory-Object-Categorization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MPSOzNnZwdkT"
   },
   "outputs": [],
   "source": [
    "def print_image(image, title):\n",
    "    \"\"\"Print the image\n",
    "\n",
    "    :param image: image pixels in list\n",
    "    :param title: title as string to be printed on top of the image\n",
    "    \"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def time_taken(start, end):\n",
    "    \"\"\"Human readable time between `start` and `end`\n",
    "\n",
    "    :param start: time.time()\n",
    "    :param end: time.time()\n",
    "    :returns: day:hour:minute:second\n",
    "    \"\"\"\n",
    "    time = end-start\n",
    "    day = time // (24 * 3600)\n",
    "    time = time % (24 * 3600)\n",
    "    hour = time // 3600\n",
    "    time %= 3600\n",
    "    minutes = time // 60\n",
    "    time %= 60\n",
    "    seconds = time\n",
    "    day_hour_min_sec = str('%02d' % int(day))+\":\"+str('%02d' % int(hour))+\":\"+str('%02d' % int(minutes))+\":\"+str('%02d' % int(seconds))\n",
    "    \n",
    "    return day_hour_min_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu6j9CyBwdkb"
   },
   "source": [
    "## Video Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8LNTE3fJwdkb"
   },
   "outputs": [],
   "source": [
    "file_0 = path+\"/dataset/EMILver1_preprocessed/EMILver1_vi_vgg16fc2_pca19/arr_0.npy\"\n",
    "file_1 = path+\"/dataset/EMILver1_preprocessed/EMILver1_vi_vgg16fc2_pca19/arr_1.npy\"\n",
    "file_2 = path+\"/dataset/EMILver1_preprocessed/EMILver1_vi_vgg16fc2_pca19/arr_2.npy\"\n",
    "video_frames = np.load(file_0, allow_pickle=True)\n",
    "action_label = np.load(file_1, allow_pickle=True)\n",
    "object_label = np.load(file_2, allow_pickle=True)\n",
    "for i in range(len(video_frames)):\n",
    "    a01 = video_frames[i]\n",
    "    while len(a01) < 658:\n",
    "        a01 = np.concatenate((a01, np.zeros((1, a01.shape[1]))))\n",
    "    video_frames[i] = a01\n",
    "video_frames = np.array(list(video_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGFHus1wwdkg"
   },
   "source": [
    "## Sound Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "81_vuxgkwdki"
   },
   "outputs": [],
   "source": [
    "file_0 = path+\"/dataset/EMILver1_preprocessed/EMILver1_au_features/arr_0.npy\"\n",
    "file_1 = path+\"/dataset/EMILver1_preprocessed/EMILver1_au_features/arr_1.npy\"\n",
    "file_2 = path+\"/dataset/EMILver1_preprocessed/EMILver1_au_features/arr_2.npy\"\n",
    "audio_frames = np.load(file_0, allow_pickle=True)\n",
    "action_label = np.load(file_1, allow_pickle=True)\n",
    "object_label = np.load(file_2, allow_pickle=True)\n",
    "for i in range(len(audio_frames)):\n",
    "    a01 = audio_frames[i]\n",
    "    while len(a01) < 658:\n",
    "        a01 = np.concatenate((a01, np.zeros((1, a01.shape[1]))))\n",
    "    audio_frames[i] = a01\n",
    "audio_frames = np.array(list(audio_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnVpmohnwdkm"
   },
   "source": [
    "## Haptic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gcL3KBdRwdkm"
   },
   "outputs": [],
   "source": [
    "file_0 = path+\"/dataset/EMILver1_preprocessed/EMILver1_sm_features/arr_0.npy\"\n",
    "file_1 = path+\"/dataset/EMILver1_preprocessed/EMILver1_sm_features/arr_1.npy\"\n",
    "file_2 = path+\"/dataset/EMILver1_preprocessed/EMILver1_sm_features/arr_2.npy\"\n",
    "haptic_frames = np.load(file_0, allow_pickle=True)\n",
    "action_label = np.load(file_1, allow_pickle=True)\n",
    "object_label = np.load(file_2, allow_pickle=True)\n",
    "for i in range(len(haptic_frames)):\n",
    "    a01 = haptic_frames[i]\n",
    "    while len(a01) < 658:\n",
    "        a01 = np.concatenate((a01, np.zeros((1, a01.shape[1]))))\n",
    "    haptic_frames[i] = a01\n",
    "haptic_frames = np.array(list(haptic_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SDTN0bc0xXDI"
   },
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "num_classes = np.nanmax(action_label)+1\n",
    "action_label_one_hot = np.zeros((len(action_label), num_classes)).astype(int)\n",
    "for i in range(len(action_label)):\n",
    "    action_label_one_hot[i, action_label[i]] = 1\n",
    "\n",
    "num_classes = np.nanmax(object_label)+1\n",
    "object_label_one_hot = np.zeros((len(object_label), num_classes)).astype(int)\n",
    "for i in range(len(object_label)):\n",
    "    object_label_one_hot[i, object_label[i]] = 1\n",
    "\n",
    "# train-test-split\n",
    "num_data = len(object_label)\n",
    "train_id, test_id = train_test_split(np.array(range(num_data)), random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eoPqSX5wdko"
   },
   "source": [
    "## Multimodal Network Hyper-parameters\n",
    "\n",
    "This network was trained for 300 epochs using Adam optimization with learning rate 1 x $10^{-4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4MOKNHywdko",
    "outputId": "cafe0028-950e-4918-9698-d0aa84924789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21269/3284197230.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Y:  Tensor(\"LabelData:0\", shape=(?, 30), dtype=float32)\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/3284197230.py:24: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Network hyper-parameters\n",
    "batch = 5\n",
    "training_epochs = 300\n",
    "display_step = 1\n",
    "\n",
    "behavior = \"grasp\"\n",
    "testset = \"testset1\"\n",
    "folder_name = behavior+'_'+testset\n",
    "model_path = path+\"/dataset/\"+folder_name+\"_logs/model.ckpt\"\n",
    "logs_path = path+\"/dataset/\"+folder_name+\"_logs/\"\n",
    "\n",
    "# num_classes = category_label_train_one_hot.shape[1]\n",
    "num_classes = object_label_one_hot.shape[1]\n",
    "\n",
    "Y = tf.placeholder('float', [None, num_classes], name='LabelData')\n",
    "print(\"Y: \", Y)\n",
    "\n",
    "video_frames_max = 658\n",
    "video_size = video_frames.shape[2]\n",
    "video_X = tf.placeholder('float', [None, video_frames_max, video_size], name='InputData')\n",
    "\n",
    "audio_frames_max = 658\n",
    "audio_size = audio_frames.shape[2]\n",
    "audio_keep_prob = tf.placeholder_with_default(1.0, shape=(), name='audio_keep')\n",
    "\n",
    "haptic_frames_max = 658\n",
    "haptic_size = haptic_frames.shape[2]\n",
    "haptic_keep_prob = tf.placeholder_with_default(1.0, shape=(), name='haptic_keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t5nIyYWewdkq"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions used to define models\n",
    "\"\"\"\n",
    "\n",
    "haptic_skip_2nd_maxpool = [\"grasp\", \"hold\", \"low\"]\n",
    "\n",
    "def model(video_data_placeholder):\n",
    "    with tf.name_scope(\"Model\"):\n",
    "        # Video\n",
    "        net = tf.layers.flatten(video_data_placeholder)\n",
    "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
    "        net = tf.layers.dropout(inputs=net)\n",
    "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
    "        net = tf.layers.dropout(inputs=net)\n",
    "        video_logits = tf.layers.dense(inputs=net, units=num_classes, activation=tf.nn.relu)\n",
    "        \n",
    "        # Audio\n",
    "        audio_data_placeholder = tf.placeholder('float', [None, audio_frames_max, audio_size], name='audio_InputData')\n",
    "        net = tf.layers.flatten(audio_data_placeholder)\n",
    "        # Dense Layer\n",
    "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
    "        net = tf.layers.dropout(inputs=net, rate=audio_keep_prob)\n",
    "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
    "        net = tf.layers.dropout(inputs=net, rate=audio_keep_prob)\n",
    "        audio_logits = tf.layers.dense(inputs=net, units=num_classes, activation=tf.nn.relu)\n",
    "        \n",
    "        # Haptic\n",
    "        haptic_data_placeholder = tf.placeholder('float', [None, haptic_frames_max, haptic_size], name='haptic_InputData')\n",
    "        net = tf.layers.flatten(haptic_data_placeholder)\n",
    "        # Dense Layer\n",
    "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
    "        net = tf.layers.dropout(inputs=net, rate=haptic_keep_prob)\n",
    "        haptic_logits = tf.layers.dense(inputs=net, units=num_classes, activation=tf.nn.relu)\n",
    "        \n",
    "        # Concatenate \n",
    "        logits = tf.concat([video_logits, audio_logits, haptic_logits], axis=1)\n",
    "        logits = tf.nn.relu(logits)\n",
    "        logits = tf.layers.dense(inputs=logits, units=num_classes)\n",
    "        \n",
    "    return logits\n",
    "\n",
    "\n",
    "def loss(prediction, label_placeholder):\n",
    "    with tf.name_scope('Loss'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=label_placeholder))\n",
    "        # Create a summary to monitor cost tensor\n",
    "        cost_scalar = tf.summary.scalar(\"loss\", cost)\n",
    "    return cost, cost_scalar\n",
    "\n",
    "def training(prediction, label_placeholder):\n",
    "    with tf.name_scope('Optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(cost)\n",
    "    return train_op\n",
    "\n",
    "def evaluate(prediction, Y):\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        # Create a summary to monitor accuracy tensor\n",
    "        accuracy_scalar = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    return accuracy, accuracy_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9YnsTz-wdkr",
    "outputId": "6c05ca52-9988-4619-dc09-465e69ca24bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21269/98775390.py:10: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/98775390.py:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/98775390.py:12: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/98775390.py:47: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/98775390.py:52: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "model_dict:  {'Model': <tf.Tensor 'Model/dense_8/BiasAdd:0' shape=(?, 30) dtype=float32>, 'Loss': <tf.Tensor 'Loss/Mean:0' shape=() dtype=float32>, 'Loss_scalar': <tf.Tensor 'Loss/loss:0' shape=() dtype=string>, 'Optimizer': <tf.Operation 'Optimizer/Adam' type=NoOp>, 'Accuracy': <tf.Tensor 'Accuracy/Mean:0' shape=() dtype=float32>, 'Accuracy_scalar': <tf.Tensor 'Accuracy/accuracy:0' shape=() dtype=string>}\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/742702177.py:23: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/742702177.py:26: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating the Neural Network\n",
    "\"\"\"\n",
    "\n",
    "model_dict = {}\n",
    "prediction = model(video_X)\n",
    "model_dict[\"Model\"] = prediction\n",
    "\n",
    "cost, cost_scalar = loss(prediction, Y)\n",
    "model_dict[\"Loss\"] = cost\n",
    "model_dict[\"Loss_scalar\"] = cost_scalar\n",
    "\n",
    "train_op = training(prediction, Y)\n",
    "model_dict[\"Optimizer\"] = train_op\n",
    "\n",
    "eval_op, accuracy_scalar = evaluate(prediction, Y)\n",
    "model_dict[\"Accuracy\"] = eval_op\n",
    "model_dict[\"Accuracy_scalar\"] = accuracy_scalar\n",
    "\n",
    "print(\"model_dict: \", model_dict)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver(max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cZj8uywlwdks"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(logs_path):\n",
    "    shutil.rmtree(logs_path)\n",
    "    os.makedirs(logs_path)\n",
    "else:\n",
    "    os.makedirs(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EymUeUC2wdks"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Writing 'Time', 'Epoch', 'Cost', 'Accuracy' in CSV file\n",
    "\"\"\"\n",
    "\n",
    "epoch_cost_accuracy = []\n",
    "epoch_cost_accuracy.append(\"Time\")\n",
    "epoch_cost_accuracy.append(\"Epoch\")\n",
    "epoch_cost_accuracy.append(\"Cost\")\n",
    "epoch_cost_accuracy.append(\"Accuracy\")\n",
    "\n",
    "with open(logs_path+folder_name+\"_data.csv\",'w') as f:\n",
    "    writer = csv.writer(f, lineterminator=\"\\n\")\n",
    "    writer.writerow(epoch_cost_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRcpBIjXwdks"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-ghKlW9wdkt",
    "outputId": "3f7d719b-9394-44e7-a2c6-4d42978e0d91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21269/2793069847.py:7: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:41:32.250730: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-02 17:41:32.279556: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394450000 Hz\n",
      "2021-12-02 17:41:32.279928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560124708090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-02 17:41:32.279945: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #216: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #157: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"core\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"core\".\n",
      "OMP: Info #192: KMP_AFFINITY: 1 socket x 4 cores/socket x 2 threads/core (4 total cores)\n",
      "OMP: Info #218: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 1 maps to socket 0 core 0 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 2 maps to socket 0 core 1 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 3 maps to socket 0 core 1 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 4 maps to socket 0 core 2 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 5 maps to socket 0 core 2 thread 1 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 6 maps to socket 0 core 3 thread 0 \n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 7 maps to socket 0 core 3 thread 1 \n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21269 thread 0 bound to OS proc set 0\n",
      "2021-12-02 17:41:32.335419: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_21269/2793069847.py:12: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_21269/2793069847.py:12: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21315 thread 1 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21314 thread 2 bound to OS proc set 4\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21319 thread 3 bound to OS proc set 6\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21320 thread 4 bound to OS proc set 1\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21321 thread 5 bound to OS proc set 3\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21322 thread 6 bound to OS proc set 5\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21324 thread 8 bound to OS proc set 0\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21323 thread 7 bound to OS proc set 7\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21326 thread 10 bound to OS proc set 4\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21327 thread 11 bound to OS proc set 6\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21328 thread 12 bound to OS proc set 1\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21325 thread 9 bound to OS proc set 2\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21329 thread 13 bound to OS proc set 3\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21330 thread 14 bound to OS proc set 5\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21331 thread 15 bound to OS proc set 7\n",
      "OMP: Info #254: KMP_AFFINITY: pid 21269 tid 21332 thread 16 bound to OS proc set 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 , Time:  00:00:00:05\n",
      "Cost - 5.8638319240676 --> Accuracy - 0.016666666915019352\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 0002 , Time:  00:00:00:09\n",
      "Cost - 2.95379562510384 --> Accuracy - 0.016666666915019352\n",
      "Epoch: 0003 , Time:  00:00:00:13\n",
      "Cost - 2.33797301517592 --> Accuracy - 0.1000000014901161\n",
      "Epoch: 0004 , Time:  00:00:00:17\n",
      "Cost - 1.86116835971673 --> Accuracy - 0.08333333457509676\n",
      "Epoch: 0005 , Time:  00:00:00:22\n",
      "Cost - 1.4803913599914 --> Accuracy - 0.15000000223517415\n",
      "Epoch: 0006 , Time:  00:00:00:26\n",
      "Cost - 1.1714843370848 --> Accuracy - 0.13333333532015482\n",
      "Epoch: 0007 , Time:  00:00:00:30\n",
      "Cost - 0.8165861972504 --> Accuracy - 0.13333333532015482\n",
      "Epoch: 0008 , Time:  00:00:00:34\n",
      "Cost - 0.60441390714711 --> Accuracy - 0.13333333532015482\n",
      "Epoch: 0009 , Time:  00:00:00:38\n",
      "Cost - 0.496376942067096 --> Accuracy - 0.13333333532015482\n",
      "Epoch: 0010 , Time:  00:00:00:42\n",
      "Cost - 0.3392734201624 --> Accuracy - 0.13333333532015482\n",
      "Epoch: 0011 , Time:  00:00:00:46\n",
      "Cost - 0.275109296147194 --> Accuracy - 0.16666667039195696\n",
      "Epoch: 0012 , Time:  00:00:00:50\n",
      "Cost - 0.14374862088718 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0013 , Time:  00:00:00:54\n",
      "Cost - 0.084849445201042 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0014 , Time:  00:00:00:58\n",
      "Cost - 0.058521096801592 --> Accuracy - 0.2000000029802322\n",
      "Epoch: 0015 , Time:  00:00:01:03\n",
      "Cost - 0.045729411248531 --> Accuracy - 0.18333333606521285\n",
      "Epoch: 0016 , Time:  00:00:01:07\n",
      "Cost - 0.036626507890307 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0017 , Time:  00:00:01:10\n",
      "Cost - 0.029471990548902 --> Accuracy - 0.18333333606521285\n",
      "Epoch: 0018 , Time:  00:00:01:14\n",
      "Cost - 0.0262045345217403 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0019 , Time:  00:00:01:18\n",
      "Cost - 0.0231286329346605 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0020 , Time:  00:00:01:22\n",
      "Cost - 0.0201976270828810 --> Accuracy - 0.18333333606521285\n",
      "Epoch: 0021 , Time:  00:00:01:30\n",
      "Cost - 0.0183382412263502 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0022 , Time:  00:00:01:37\n",
      "Cost - 0.016195695808467 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0023 , Time:  00:00:01:42\n",
      "Cost - 0.0147550906080545 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0024 , Time:  00:00:01:46\n",
      "Cost - 0.013438970820667 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0025 , Time:  00:00:01:50\n",
      "Cost - 0.012220721239120 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0026 , Time:  00:00:01:54\n",
      "Cost - 0.0112881769633127 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0027 , Time:  00:00:01:58\n",
      "Cost - 0.0103875079399181 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0028 , Time:  00:00:02:02\n",
      "Cost - 0.0096861387654725 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0029 , Time:  00:00:02:06\n",
      "Cost - 0.009051031846967 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0030 , Time:  00:00:02:10\n",
      "Cost - 0.0083567017184880 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0031 , Time:  00:00:02:14\n",
      "Cost - 0.0078132436158032 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0032 , Time:  00:00:02:18\n",
      "Cost - 0.0072714719572104 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0033 , Time:  00:00:02:22\n",
      "Cost - 0.0068919326036444 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0034 , Time:  00:00:02:27\n",
      "Cost - 0.0064964503981173 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0035 , Time:  00:00:02:31\n",
      "Cost - 0.0062020476907491 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0036 , Time:  00:00:02:34\n",
      "Cost - 0.0057619838302748 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0037 , Time:  00:00:02:38\n",
      "Cost - 0.0054596087850061 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0038 , Time:  00:00:02:43\n",
      "Cost - 0.0051785402433274 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0039 , Time:  00:00:02:47\n",
      "Cost - 0.0048972074421019 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0040 , Time:  00:00:02:51\n",
      "Cost - 0.0046617191821698 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0041 , Time:  00:00:02:55\n",
      "Cost - 0.00443840164290223 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0042 , Time:  00:00:03:00\n",
      "Cost - 0.0042279019900080 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0043 , Time:  00:00:03:04\n",
      "Cost - 0.0039968425957744 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0044 , Time:  00:00:03:08\n",
      "Cost - 0.00381170604507335 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0045 , Time:  00:00:03:13\n",
      "Cost - 0.0036320759714322 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0046 , Time:  00:00:03:17\n",
      "Cost - 0.00349482957972213 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0047 , Time:  00:00:03:21\n",
      "Cost - 0.0033397187168399 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0048 , Time:  00:00:03:26\n",
      "Cost - 0.00318243983525058 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0049 , Time:  00:00:03:30\n",
      "Cost - 0.003066632553883 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0050 , Time:  00:00:03:34\n",
      "Cost - 0.002930676600145 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0051 , Time:  00:00:03:39\n",
      "Cost - 0.00281136730659 --> Accuracy - 0.1666666691501935\n",
      "Epoch: 0052 , Time:  00:00:03:43\n",
      "Cost - 0.0026911325597514 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0053 , Time:  00:00:03:47\n",
      "Cost - 0.00257809820403862 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0054 , Time:  00:00:03:51\n",
      "Cost - 0.00249634336796589 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0055 , Time:  00:00:03:56\n",
      "Cost - 0.00239901267276662 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0056 , Time:  00:00:04:00\n",
      "Cost - 0.00230067621709571 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0057 , Time:  00:00:04:04\n",
      "Cost - 0.00221593149601378 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0058 , Time:  00:00:04:09\n",
      "Cost - 0.00212903272606328 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0059 , Time:  00:00:04:13\n",
      "Cost - 0.00205850019766431 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0060 , Time:  00:00:04:20\n",
      "Cost - 0.00199094033127443 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0061 , Time:  00:00:04:28\n",
      "Cost - 0.00191980515794259 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0062 , Time:  00:00:04:33\n",
      "Cost - 0.00184180996438953 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0063 , Time:  00:00:04:37\n",
      "Cost - 0.00177802174584940 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0064 , Time:  00:00:04:40\n",
      "Cost - 0.0017180450231535 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0065 , Time:  00:00:04:45\n",
      "Cost - 0.0016782153721174 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0066 , Time:  00:00:04:50\n",
      "Cost - 0.00161285181982546 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0067 , Time:  00:00:04:54\n",
      "Cost - 0.00155676414821452 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0068 , Time:  00:00:04:59\n",
      "Cost - 0.00150759789782265 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0069 , Time:  00:00:05:03\n",
      "Cost - 0.00145665292479356 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0070 , Time:  00:00:05:08\n",
      "Cost - 0.00140512815010475 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0071 , Time:  00:00:05:12\n",
      "Cost - 0.00136239228757201 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0072 , Time:  00:00:05:16\n",
      "Cost - 0.00132629169739731 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0073 , Time:  00:00:05:20\n",
      "Cost - 0.00128518760013523 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0074 , Time:  00:00:05:24\n",
      "Cost - 0.00123868730022675 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0075 , Time:  00:00:05:29\n",
      "Cost - 0.0011972032467989 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0076 , Time:  00:00:05:33\n",
      "Cost - 0.0011689633845687 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0077 , Time:  00:00:05:37\n",
      "Cost - 0.00112529462785460 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0078 , Time:  00:00:05:41\n",
      "Cost - 0.00109688826422724 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0079 , Time:  00:00:05:45\n",
      "Cost - 0.0010669875086427 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0080 , Time:  00:00:05:49\n",
      "Cost - 0.00103203448331138 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0081 , Time:  00:00:05:53\n",
      "Cost - 0.00099796453933878 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0082 , Time:  00:00:05:58\n",
      "Cost - 0.00096888809316118 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0083 , Time:  00:00:06:02\n",
      "Cost - 0.0009433982728902 --> Accuracy - 0.18333333606521288\n",
      "Epoch: 0084 , Time:  00:00:06:06\n",
      "Cost - 0.00092141087225172 --> Accuracy - 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0085 , Time:  00:00:06:10\n",
      "Cost - 0.00089364455197937 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0086 , Time:  00:00:06:14\n",
      "Cost - 0.00086461078899446 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0087 , Time:  00:00:06:18\n",
      "Cost - 0.00084332484564381 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0088 , Time:  00:00:06:22\n",
      "Cost - 0.00081978233275650 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0089 , Time:  00:00:06:26\n",
      "Cost - 0.00079672044699287 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0090 , Time:  00:00:06:31\n",
      "Cost - 0.00077628210743164 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0091 , Time:  00:00:06:35\n",
      "Cost - 0.00075362839076357 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0092 , Time:  00:00:06:39\n",
      "Cost - 0.00073224128330669 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0093 , Time:  00:00:06:43\n",
      "Cost - 0.00071350790353284 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0094 , Time:  00:00:06:47\n",
      "Cost - 0.00069618676489982 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0095 , Time:  00:00:06:51\n",
      "Cost - 0.00067747798069225 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0096 , Time:  00:00:06:56\n",
      "Cost - 0.00066045511387831 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0097 , Time:  00:00:07:00\n",
      "Cost - 0.00064216484639069 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0098 , Time:  00:00:07:04\n",
      "Cost - 0.00062726798730889 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0099 , Time:  00:00:07:08\n",
      "Cost - 0.00060917525883673 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0100 , Time:  00:00:07:12\n",
      "Cost - 0.0005961366542679 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0101 , Time:  00:00:07:16\n",
      "Cost - 0.00057931780368865 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0102 , Time:  00:00:07:20\n",
      "Cost - 0.00056495353621560 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0103 , Time:  00:00:07:29\n",
      "Cost - 0.00054891244831701 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0104 , Time:  00:00:07:35\n",
      "Cost - 0.00053727980371655 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0105 , Time:  00:00:07:40\n",
      "Cost - 0.00052313147494310 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0106 , Time:  00:00:07:44\n",
      "Cost - 0.00051074593243861 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0107 , Time:  00:00:07:48\n",
      "Cost - 0.00049822453042401 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0108 , Time:  00:00:07:52\n",
      "Cost - 0.00048711596456188 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0109 , Time:  00:00:07:56\n",
      "Cost - 0.00047412005571661 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0110 , Time:  00:00:08:00\n",
      "Cost - 0.000462372378630486 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0111 , Time:  00:00:08:04\n",
      "Cost - 0.00044938333788498 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0112 , Time:  00:00:08:08\n",
      "Cost - 0.00043789455230580 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0113 , Time:  00:00:08:12\n",
      "Cost - 0.00042801073262429 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0114 , Time:  00:00:08:16\n",
      "Cost - 0.00041772120069557 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0115 , Time:  00:00:08:20\n",
      "Cost - 0.000409209047777241 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0116 , Time:  00:00:08:24\n",
      "Cost - 0.00039751657297731 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0117 , Time:  00:00:08:28\n",
      "Cost - 0.000388511559221013 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0118 , Time:  00:00:08:32\n",
      "Cost - 0.000377737855160375 --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0119 , Time:  00:00:08:36\n",
      "Cost - 0.00036718193021240 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0120 , Time:  00:00:08:39\n",
      "Cost - 0.0003577350180421 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0121 , Time:  00:00:08:44\n",
      "Cost - 0.000350009943051393 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0122 , Time:  00:00:08:48\n",
      "Cost - 0.0003415467104383 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0123 , Time:  00:00:08:52\n",
      "Cost - 0.00033337276909151 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0124 , Time:  00:00:08:56\n",
      "Cost - 0.000324618963835140 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0125 , Time:  00:00:09:00\n",
      "Cost - 0.000316619039141288 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0126 , Time:  00:00:09:03\n",
      "Cost - 0.00030893665906559 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0127 , Time:  00:00:09:08\n",
      "Cost - 0.00030220240013376 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0128 , Time:  00:00:09:12\n",
      "Cost - 0.000295340286862079 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0129 , Time:  00:00:09:16\n",
      "Cost - 0.000286937237938723 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0130 , Time:  00:00:09:20\n",
      "Cost - 0.0002803155516125 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0131 , Time:  00:00:09:24\n",
      "Cost - 0.000274485347795 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0132 , Time:  00:00:09:28\n",
      "Cost - 0.000267680562198317 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0133 , Time:  00:00:09:32\n",
      "Cost - 0.00026067517804525 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0134 , Time:  00:00:09:37\n",
      "Cost - 0.00025548504547461 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0135 , Time:  00:00:09:41\n",
      "Cost - 0.000249581355496451 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0136 , Time:  00:00:09:46\n",
      "Cost - 0.000244012469718452 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0137 , Time:  00:00:09:49\n",
      "Cost - 0.000238107783742533 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0138 , Time:  00:00:09:54\n",
      "Cost - 0.00023247867122538 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0139 , Time:  00:00:09:58\n",
      "Cost - 0.000227974776660428 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0140 , Time:  00:00:10:02\n",
      "Cost - 0.000221962666627304 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0141 , Time:  00:00:10:06\n",
      "Cost - 0.00021713968979181 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0142 , Time:  00:00:10:10\n",
      "Cost - 0.000212601362363784 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0143 , Time:  00:00:10:14\n",
      "Cost - 0.000207323564407286 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0144 , Time:  00:00:10:18\n",
      "Cost - 0.000202887779475228 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0145 , Time:  00:00:10:23\n",
      "Cost - 0.000198282486962852 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0146 , Time:  00:00:10:29\n",
      "Cost - 0.0001932169545600 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0147 , Time:  00:00:10:35\n",
      "Cost - 0.000190062690914298 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0148 , Time:  00:00:10:38\n",
      "Cost - 0.000185715469948869 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0149 , Time:  00:00:10:43\n",
      "Cost - 0.00018079033988114 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0150 , Time:  00:00:10:47\n",
      "Cost - 0.000177661833024305 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0151 , Time:  00:00:10:52\n",
      "Cost - 0.0001731332035382 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0152 , Time:  00:00:10:57\n",
      "Cost - 0.000169220182013102 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0153 , Time:  00:00:11:02\n",
      "Cost - 0.000165695191551801 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0154 , Time:  00:00:11:07\n",
      "Cost - 0.000162218972440718 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0155 , Time:  00:00:11:12\n",
      "Cost - 0.000158270919402841 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0156 , Time:  00:00:11:17\n",
      "Cost - 0.000155810461769255 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0157 , Time:  00:00:11:21\n",
      "Cost - 0.000151389544751307 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0158 , Time:  00:00:11:26\n",
      "Cost - 0.000148521269592391 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0159 , Time:  00:00:11:30\n",
      "Cost - 0.000144988126824803 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0160 , Time:  00:00:11:34\n",
      "Cost - 0.000142196587653921 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0161 , Time:  00:00:11:38\n",
      "Cost - 0.000138856832967980 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0162 , Time:  00:00:11:43\n",
      "Cost - 0.00013552892212626 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0163 , Time:  00:00:11:47\n",
      "Cost - 0.00013318038327270 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0164 , Time:  00:00:11:52\n",
      "Cost - 0.00013010733891860 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0165 , Time:  00:00:11:56\n",
      "Cost - 0.00012742368724300 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0166 , Time:  00:00:12:00\n",
      "Cost - 0.000124724814466187 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0167 , Time:  00:00:12:05\n",
      "Cost - 0.000121935153098699 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0168 , Time:  00:00:12:09\n",
      "Cost - 0.000118903821708550 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0169 , Time:  00:00:12:14\n",
      "Cost - 0.000116508150818440 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0170 , Time:  00:00:12:18\n",
      "Cost - 0.00011407535627464 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0171 , Time:  00:00:12:23\n",
      "Cost - 0.000112000159485129 --> Accuracy - 0.2166666698952516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0172 , Time:  00:00:12:27\n",
      "Cost - 0.000108970131704053 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0173 , Time:  00:00:12:32\n",
      "Cost - 0.000106953195326140 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0174 , Time:  00:00:12:37\n",
      "Cost - 0.000104468718139590 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0175 , Time:  00:00:12:41\n",
      "Cost - 0.000102192889850509 --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0176 , Time:  00:00:12:46\n",
      "Cost - 9.997259813745687e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0177 , Time:  00:00:12:50\n",
      "Cost - 9.774703165829933e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0178 , Time:  00:00:12:54\n",
      "Cost - 9.582277016306763e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0179 , Time:  00:00:12:59\n",
      "Cost - 9.385674527746031e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0180 , Time:  00:00:13:04\n",
      "Cost - 9.147488951081567e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0181 , Time:  00:00:13:08\n",
      "Cost - 8.935261282911395e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0182 , Time:  00:00:13:13\n",
      "Cost - 8.796530316127853e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0183 , Time:  00:00:13:17\n",
      "Cost - 8.595490483761144e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0184 , Time:  00:00:13:21\n",
      "Cost - 8.412727417332161e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0185 , Time:  00:00:13:25\n",
      "Cost - 8.251882597202588e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0186 , Time:  00:00:13:30\n",
      "Cost - 8.054483199278667e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0187 , Time:  00:00:13:34\n",
      "Cost - 7.907673777178086e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0188 , Time:  00:00:13:38\n",
      "Cost - 7.710937249309306e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0189 , Time:  00:00:13:43\n",
      "Cost - 7.545585756613742e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0190 , Time:  00:00:13:50\n",
      "Cost - 7.397054499354758e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0191 , Time:  00:00:13:56\n",
      "Cost - 7.231241139985894e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0192 , Time:  00:00:14:00\n",
      "Cost - 7.067148256586127e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0193 , Time:  00:00:14:04\n",
      "Cost - 6.937950163571966e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0194 , Time:  00:00:14:08\n",
      "Cost - 6.789021699660225e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0195 , Time:  00:00:14:13\n",
      "Cost - 6.647243096975014e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0196 , Time:  00:00:14:17\n",
      "Cost - 6.513013300314521e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0197 , Time:  00:00:14:21\n",
      "Cost - 6.400899726739025e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0198 , Time:  00:00:14:25\n",
      "Cost - 6.229190502280188e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0199 , Time:  00:00:14:29\n",
      "Cost - 6.109925834607566e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0200 , Time:  00:00:14:34\n",
      "Cost - 5.971921301453321e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0201 , Time:  00:00:14:38\n",
      "Cost - 5.8921882605823666e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0202 , Time:  00:00:14:43\n",
      "Cost - 5.738225303907207e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0203 , Time:  00:00:14:47\n",
      "Cost - 5.605648907981554e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0204 , Time:  00:00:14:51\n",
      "Cost - 5.497507623254529e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0205 , Time:  00:00:14:56\n",
      "Cost - 5.378308530149903e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0206 , Time:  00:00:15:01\n",
      "Cost - 5.275532162664199e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0207 , Time:  00:00:15:05\n",
      "Cost - 5.1642790822370443e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0208 , Time:  00:00:15:09\n",
      "Cost - 5.04746260250815e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0209 , Time:  00:00:15:14\n",
      "Cost - 4.9380637089295e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0210 , Time:  00:00:15:18\n",
      "Cost - 4.835882721939319e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0211 , Time:  00:00:15:22\n",
      "Cost - 4.7450253279950833e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0212 , Time:  00:00:15:28\n",
      "Cost - 4.640723859160466e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0213 , Time:  00:00:15:32\n",
      "Cost - 4.542847020477186e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0214 , Time:  00:00:15:37\n",
      "Cost - 4.44099580616037e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0215 , Time:  00:00:15:41\n",
      "Cost - 4.352124794119542e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0216 , Time:  00:00:15:45\n",
      "Cost - 4.265306390354656e- --> Accuracy - 0.2166666698952516\n",
      "Epoch: 0217 , Time:  00:00:15:49\n",
      "Cost - 4.172924354861609e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0218 , Time:  00:00:15:54\n",
      "Cost - 4.081933800787536e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0219 , Time:  00:00:15:58\n",
      "Cost - 3.999551836386673e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0220 , Time:  00:00:16:03\n",
      "Cost - 3.914653290040505e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0221 , Time:  00:00:16:09\n",
      "Cost - 3.842933038969124e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0222 , Time:  00:00:16:14\n",
      "Cost - 3.754524813201795e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0223 , Time:  00:00:16:18\n",
      "Cost - 3.685387011703117e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0224 , Time:  00:00:16:22\n",
      "Cost - 3.6043290063187466e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0225 , Time:  00:00:16:27\n",
      "Cost - 3.542674413539417e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0226 , Time:  00:00:16:31\n",
      "Cost - 3.473205672182505e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0227 , Time:  00:00:16:35\n",
      "Cost - 3.385128143741491e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0228 , Time:  00:00:16:39\n",
      "Cost - 3.3183078256923996e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0229 , Time:  00:00:16:43\n",
      "Cost - 3.2522160280576725e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0230 , Time:  00:00:16:47\n",
      "Cost - 3.187912393008851e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0231 , Time:  00:00:16:52\n",
      "Cost - 3.127648410049409e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0232 , Time:  00:00:16:56\n",
      "Cost - 3.0649337026665715e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0233 , Time:  00:00:17:00\n",
      "Cost - 3.004007365032319e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0234 , Time:  00:00:17:05\n",
      "Cost - 2.9291079044924114e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0235 , Time:  00:00:17:11\n",
      "Cost - 2.871558505527597e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0236 , Time:  00:00:17:17\n",
      "Cost - 2.8142744743793927e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0237 , Time:  00:00:17:22\n",
      "Cost - 2.7579833790191012e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0238 , Time:  00:00:17:26\n",
      "Cost - 2.7061953561416078e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0239 , Time:  00:00:17:30\n",
      "Cost - 2.644805224210561e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0240 , Time:  00:00:17:34\n",
      "Cost - 2.5947389430156265e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0241 , Time:  00:00:17:38\n",
      "Cost - 2.5463952296276053e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0242 , Time:  00:00:17:42\n",
      "Cost - 2.486395235084476e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0243 , Time:  00:00:17:47\n",
      "Cost - 2.437852210985309e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0244 , Time:  00:00:17:51\n",
      "Cost - 2.389773094869775e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0245 , Time:  00:00:17:55\n",
      "Cost - 2.3445412681313537e- --> Accuracy - 0.20000000298023224\n",
      "Epoch: 0246 , Time:  00:00:17:59\n",
      "Cost - 2.2907002201261803e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0247 , Time:  00:00:18:03\n",
      "Cost - 2.245932101787832e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0248 , Time:  00:00:18:08\n",
      "Cost - 2.2044085628496966e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0249 , Time:  00:00:18:12\n",
      "Cost - 2.1542100133350076e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0250 , Time:  00:00:18:16\n",
      "Cost - 2.1054682318006405e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0251 , Time:  00:00:18:20\n",
      "Cost - 2.0673887446618108e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0252 , Time:  00:00:18:25\n",
      "Cost - 2.0235474443729294e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0253 , Time:  00:00:18:29\n",
      "Cost - 1.977984367032251e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0254 , Time:  00:00:18:33\n",
      "Cost - 1.9344742061851623e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0255 , Time:  00:00:18:37\n",
      "Cost - 1.8924872266426162e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0256 , Time:  00:00:18:41\n",
      "Cost - 1.8548711649499532e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0257 , Time:  00:00:18:46\n",
      "Cost - 1.8232815515754432e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0258 , Time:  00:00:18:50\n",
      "Cost - 1.781691781212026e- --> Accuracy - 0.21666666989525157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0259 , Time:  00:00:18:55\n",
      "Cost - 1.7418239723257204e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0260 , Time:  00:00:18:59\n",
      "Cost - 1.7070554122256e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0261 , Time:  00:00:19:03\n",
      "Cost - 1.67520081251698e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0262 , Time:  00:00:19:07\n",
      "Cost - 1.6416907353939477e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0263 , Time:  00:00:19:11\n",
      "Cost - 1.602220159687325e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0264 , Time:  00:00:19:15\n",
      "Cost - 1.5765906987831433e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0265 , Time:  00:00:19:20\n",
      "Cost - 1.5438750867562907e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0266 , Time:  00:00:19:24\n",
      "Cost - 1.513543638035723e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0267 , Time:  00:00:19:28\n",
      "Cost - 1.4759935488149897e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0268 , Time:  00:00:19:32\n",
      "Cost - 1.4504303256520261e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0269 , Time:  00:00:19:36\n",
      "Cost - 1.4197015085907573e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0270 , Time:  00:00:19:40\n",
      "Cost - 1.3914892355791784e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0271 , Time:  00:00:19:45\n",
      "Cost - 1.3643365074737328e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0272 , Time:  00:00:19:49\n",
      "Cost - 1.3381109586892608e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0273 , Time:  00:00:19:53\n",
      "Cost - 1.3141371722566773e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0274 , Time:  00:00:19:57\n",
      "Cost - 1.2827459765200423e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0275 , Time:  00:00:20:01\n",
      "Cost - 1.2567191156954828e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0276 , Time:  00:00:20:06\n",
      "Cost - 1.2357916602923069e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0277 , Time:  00:00:20:12\n",
      "Cost - 1.2089037309376892e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0278 , Time:  00:00:20:18\n",
      "Cost - 1.1835391609969925e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0279 , Time:  00:00:20:22\n",
      "Cost - 1.1630752624114395e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0280 , Time:  00:00:20:27\n",
      "Cost - 1.1351940303130605e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0281 , Time:  00:00:20:31\n",
      "Cost - 1.1143989733379083e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0282 , Time:  00:00:20:35\n",
      "Cost - 1.0922131865400945e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0283 , Time:  00:00:20:40\n",
      "Cost - 1.0696961996675073e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0284 , Time:  00:00:20:44\n",
      "Cost - 1.0500269986045572e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0285 , Time:  00:00:20:48\n",
      "Cost - 1.0266490853104591e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0286 , Time:  00:00:20:53\n",
      "Cost - 1.0065824716952597e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0287 , Time:  00:00:20:57\n",
      "Cost - 9.875754901461023e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0288 , Time:  00:00:21:02\n",
      "Cost - 9.654559335103842e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0289 , Time:  00:00:21:06\n",
      "Cost - 9.482370223344738e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0290 , Time:  00:00:21:10\n",
      "Cost - 9.292300155215748e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0291 , Time:  00:00:21:15\n",
      "Cost - 9.141304076365485e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0292 , Time:  00:00:21:18\n",
      "Cost - 8.95785641811623e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0293 , Time:  00:00:21:23\n",
      "Cost - 8.739971450369112e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0294 , Time:  00:00:21:27\n",
      "Cost - 8.561159366612022e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0295 , Time:  00:00:21:31\n",
      "Cost - 8.368440275161347e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0296 , Time:  00:00:21:36\n",
      "Cost - 8.208172251518897e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0297 , Time:  00:00:21:41\n",
      "Cost - 8.03399595699577e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0298 , Time:  00:00:21:45\n",
      "Cost - 7.900218229729539e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0299 , Time:  00:00:21:49\n",
      "Cost - 7.725380063069071e- --> Accuracy - 0.21666666989525157\n",
      "Epoch: 0300 , Time:  00:00:21:53\n",
      "Cost - 7.552528466526887e- --> Accuracy - 0.21666666989525157\n",
      "Optimization Finished!\n",
      "Time taken: day, hour, minutes, seconds-> 00:00:21:53\n"
     ]
    }
   ],
   "source": [
    "\"\"\"## Training\"\"\"\n",
    "\n",
    "# Start Training\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost_list = 0.0\n",
    "        total_batch = int(len(train_id)/batch)\n",
    "        \n",
    "        # Shuffle data\n",
    "        np.random.shuffle(train_id)\n",
    "        \n",
    "        i = 0\n",
    "        # Loop over all batches\n",
    "        for start, end in zip(range(0, len(train_id), batch), range(batch, len(train_id)+1, batch)):\n",
    "            video_input_data, label_data = video_frames[train_id][start:end], object_label_one_hot[train_id][start:end]\n",
    "\n",
    "            audio_input_data = audio_frames[train_id][start:end]\n",
    "            audio_X = tf.get_default_graph().get_tensor_by_name(\"Model/audio_InputData:0\")\n",
    "\n",
    "            haptic_input_data = haptic_frames[train_id][start:end]\n",
    "            haptic_X = tf.get_default_graph().get_tensor_by_name(\"Model/haptic_InputData:0\")\n",
    "\n",
    "            _, new_cost, cost_scalar = sess.run(\n",
    "                [model_dict[\"Optimizer\"], model_dict[\"Loss\"], model_dict[\"Loss_scalar\"]], \n",
    "                feed_dict={\n",
    "                    video_X: video_input_data, \n",
    "                    audio_X: audio_input_data, \n",
    "                    haptic_X: haptic_input_data, \n",
    "                    Y: label_data, \n",
    "                    audio_keep_prob: 0.5, \n",
    "                    haptic_keep_prob: 0.5\n",
    "                    }\n",
    "                )\n",
    "            # Compute average loss\n",
    "            avg_cost_list += new_cost/total_batch\n",
    "\n",
    "            summary_writer.add_summary(cost_scalar, epoch * total_batch + i)\n",
    "            i += 1\n",
    "        save_path = saver.save(sess, model_path, epoch)\n",
    "         \n",
    "        # Calculate Accuracy\n",
    "        avg_accuracy_list = 0.0\n",
    "        total_batch = int(len(test_id)/batch)\n",
    "        i = 0\n",
    "        for start, end in zip(range(0, len(test_id), batch), range(batch, len(test_id)+1, batch)):\n",
    "            video_input_data, label_data = video_frames[test_id][start:end], object_label_one_hot[test_id][start:end]\n",
    "\n",
    "            audio_input_data = audio_frames[test_id][start:end]\n",
    "            audio_X = tf.get_default_graph().get_tensor_by_name(\"Model/audio_InputData:0\")\n",
    "\n",
    "            haptic_input_data = haptic_frames[test_id][start:end]\n",
    "            haptic_X = tf.get_default_graph().get_tensor_by_name(\"Model/haptic_InputData:0\")\n",
    "\n",
    "            accuracy, accuracy_scalar = sess.run([model_dict[\"Accuracy\"], model_dict[\"Accuracy_scalar\"]], feed_dict={video_X: video_input_data, audio_X: audio_input_data, haptic_X: haptic_input_data, Y: label_data, audio_keep_prob: 1.0, haptic_keep_prob: 1.0})\n",
    "            # Compute average accuracy\n",
    "            avg_accuracy_list += accuracy/total_batch\n",
    "            summary_writer.add_summary(accuracy_scalar, epoch * total_batch + i)\n",
    "            i += 1\n",
    "        \n",
    "        # Printing current epoch accuracy\n",
    "        epoch_cost_accuracy = []\n",
    "        epoch_cost_accuracy.append(time_taken(start_time, time.time()))\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \", Time: \", time_taken(start_time, time.time()))\n",
    "            a_string = \"Cost - \"\n",
    "            epoch_cost_accuracy.append(epoch+1)\n",
    "            \n",
    "            a_string += str(avg_cost_list)\n",
    "            epoch_cost_accuracy.append(str(avg_cost_list))\n",
    "            \n",
    "            a_string = a_string[0:-2]+\" --> Accuracy - \"\n",
    "            a_string += str(avg_accuracy_list)\n",
    "            epoch_cost_accuracy.append(str(avg_accuracy_list))\n",
    "            \n",
    "            print(a_string)\n",
    "        \n",
    "        # Writing current epoch data\n",
    "        with open(logs_path+folder_name+\"_data.csv\", 'a') as f: # append to the file created\n",
    "            writer = csv.writer(f, lineterminator=\"\\n\")\n",
    "            writer.writerow(epoch_cost_accuracy)\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "    end_time = time.time()\n",
    "    print(\"Time taken: day, hour, minutes, seconds->\", time_taken(start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taheBWu21g_M",
    "outputId": "f4dc0491-810b-4c06-c71c-8d7f98cf1a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in the file /home/alex/Deep-Multi-Sensory-Object-Categorization/dataset/grasp_testset1_logs/grasp_testset1_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Results are saved in the file \" + logs_path+folder_name+\"_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwypniZG1sIV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "MultimodalNetworkTrainingEMIL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
