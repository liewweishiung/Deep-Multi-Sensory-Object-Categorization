{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "MultimodalNetworkTrainingEMIL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kAVXf8Owdj_"
      },
      "source": [
        "# Multimodal Classification Training\n",
        "\n",
        "This notebook creates the Multimodal Network Architecture and trains it for grasp testset1. After training the network weights will be stored in the folder `./dataset/grasp_testset1_logs`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9PQVYgswdkG"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "`Python 3.5.4` is used for development and following packages are required to run the code provided in the notebook:\n",
        "\n",
        "`pip install googledrivedownloader`<br>\n",
        "`pip install matplotlib`<br>\n",
        "`pip install tensorflow-gpu`<br>\n",
        "`pip install keras`<br>\n",
        "`pip install numpy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN0aShvGw1pt",
        "outputId": "be7b5555-28a1-426b-83d8-a9aa76130d78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onu-rrTryUqx",
        "outputId": "aefb2778-7e10-46e3-8aae-b6a9bed129fc"
      },
      "source": [
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 53.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.13.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.42.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=3bd31ca537ac771fe1aa6ed7204d643308b73889d4792d7fef57779a2cbf5d68\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 13.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "Successfully installed keras-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkd2IbswwdkJ"
      },
      "source": [
        "import os, csv, time, shutil\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "path=\"/content/drive/MyDrive/Deep-Multi-Sensory-Object-Categorization\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPSOzNnZwdkT"
      },
      "source": [
        "def print_image(image, title):\n",
        "    \"\"\"Print the image\n",
        "\n",
        "    :param image: image pixels in list\n",
        "    :param title: title as string to be printed on top of the image\n",
        "    \"\"\"\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def time_taken(start, end):\n",
        "    \"\"\"Human readable time between `start` and `end`\n",
        "\n",
        "    :param start: time.time()\n",
        "    :param end: time.time()\n",
        "    :returns: day:hour:minute:second\n",
        "    \"\"\"\n",
        "    time = end-start\n",
        "    day = time // (24 * 3600)\n",
        "    time = time % (24 * 3600)\n",
        "    hour = time // 3600\n",
        "    time %= 3600\n",
        "    minutes = time // 60\n",
        "    time %= 60\n",
        "    seconds = time\n",
        "    day_hour_min_sec = str('%02d' % int(day))+\":\"+str('%02d' % int(hour))+\":\"+str('%02d' % int(minutes))+\":\"+str('%02d' % int(seconds))\n",
        "    \n",
        "    return day_hour_min_sec"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu6j9CyBwdkb"
      },
      "source": [
        "## Video Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LNTE3fJwdkb"
      },
      "source": [
        "file_0 = path+\"/dataset/EMILver1_preprocessed/EMILver1_vi_vgg16fc2_pca19/arr_0.npy\"\n",
        "file_1 = path+\"/dataset/EMILver1_preprocessed/EMILver1_vi_vgg16fc2_pca19/arr_1.npy\"\n",
        "file_2 = path+\"/dataset/EMILver1_preprocessed/EMILver1_vi_vgg16fc2_pca19/arr_2.npy\"\n",
        "video_frames = np.load(file_0, allow_pickle=True)\n",
        "action_label = np.load(file_1, allow_pickle=True)\n",
        "object_label = np.load(file_2, allow_pickle=True)\n",
        "for i in range(len(video_frames)):\n",
        "    a01 = video_frames[i]\n",
        "    while len(a01) < 658:\n",
        "        a01 = np.concatenate((a01, np.zeros((1, a01.shape[1]))))\n",
        "    video_frames[i] = a01\n",
        "video_frames = np.array(list(video_frames))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGFHus1wwdkg"
      },
      "source": [
        "## Sound Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81_vuxgkwdki"
      },
      "source": [
        "file_0 = path+\"/dataset/EMILver1_preprocessed/EMILver1_au_features/arr_0.npy\"\n",
        "file_1 = path+\"/dataset/EMILver1_preprocessed/EMILver1_au_features/arr_1.npy\"\n",
        "file_2 = path+\"/dataset/EMILver1_preprocessed/EMILver1_au_features/arr_2.npy\"\n",
        "audio_frames = np.load(file_0, allow_pickle=True)\n",
        "action_label = np.load(file_1, allow_pickle=True)\n",
        "object_label = np.load(file_2, allow_pickle=True)\n",
        "for i in range(len(audio_frames)):\n",
        "    a01 = audio_frames[i]\n",
        "    while len(a01) < 658:\n",
        "        a01 = np.concatenate((a01, np.zeros((1, a01.shape[1]))))\n",
        "    audio_frames[i] = a01\n",
        "audio_frames = np.array(list(audio_frames))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnVpmohnwdkm"
      },
      "source": [
        "## Haptic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcL3KBdRwdkm"
      },
      "source": [
        "file_0 = path+\"/dataset/EMILver1_preprocessed/EMILver1_sm_features/arr_0.npy\"\n",
        "file_1 = path+\"/dataset/EMILver1_preprocessed/EMILver1_sm_features/arr_1.npy\"\n",
        "file_2 = path+\"/dataset/EMILver1_preprocessed/EMILver1_sm_features/arr_2.npy\"\n",
        "haptic_frames = np.load(file_0, allow_pickle=True)\n",
        "action_label = np.load(file_1, allow_pickle=True)\n",
        "object_label = np.load(file_2, allow_pickle=True)\n",
        "for i in range(len(haptic_frames)):\n",
        "    a01 = haptic_frames[i]\n",
        "    while len(a01) < 658:\n",
        "        a01 = np.concatenate((a01, np.zeros((1, a01.shape[1]))))\n",
        "    haptic_frames[i] = a01\n",
        "haptic_frames = np.array(list(haptic_frames))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDTN0bc0xXDI"
      },
      "source": [
        "# one-hot encoding\n",
        "num_classes = np.nanmax(action_label)+1\n",
        "action_label_one_hot = np.zeros((len(action_label), num_classes)).astype(int)\n",
        "for i in range(len(action_label)):\n",
        "    action_label_one_hot[i, action_label[i]] = 1\n",
        "\n",
        "num_classes = np.nanmax(object_label)+1\n",
        "object_label_one_hot = np.zeros((len(object_label), num_classes)).astype(int)\n",
        "for i in range(len(object_label)):\n",
        "    object_label_one_hot[i, object_label[i]] = 1\n",
        "\n",
        "# train-test-split\n",
        "num_data = len(object_label)\n",
        "train_id, test_id = train_test_split(np.array(range(num_data)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eoPqSX5wdko"
      },
      "source": [
        "## Multimodal Network Hyper-parameters\n",
        "\n",
        "This network was trained for 300 epochs using Adam optimization with learning rate 1 x $10^{-4}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4MOKNHywdko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cafe0028-950e-4918-9698-d0aa84924789"
      },
      "source": [
        "# Network hyper-parameters\n",
        "batch = 5\n",
        "training_epochs = 300\n",
        "display_step = 1\n",
        "\n",
        "behavior = \"grasp\"\n",
        "testset = \"testset1\"\n",
        "folder_name = behavior+'_'+testset\n",
        "model_path = \"./dataset/\"+folder_name+\"_logs/model.ckpt\"\n",
        "logs_path = \"./dataset/\"+folder_name+\"_logs/\"\n",
        "\n",
        "# num_classes = category_label_train_one_hot.shape[1]\n",
        "num_classes = object_label_one_hot.shape[1]\n",
        "\n",
        "Y = tf.placeholder('float', [None, num_classes], name='LabelData')\n",
        "print(\"Y: \", Y)\n",
        "\n",
        "video_frames_max = 658\n",
        "video_size = video_frames.shape[2]\n",
        "video_X = tf.placeholder('float', [None, video_frames_max, video_size], name='InputData')\n",
        "\n",
        "audio_frames_max = 658\n",
        "audio_size = audio_frames.shape[2]\n",
        "audio_keep_prob = tf.placeholder_with_default(1.0, shape=(), name='audio_keep')\n",
        "\n",
        "haptic_frames_max = 658\n",
        "haptic_size = haptic_frames.shape[2]\n",
        "haptic_keep_prob = tf.placeholder_with_default(1.0, shape=(), name='haptic_keep')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y:  Tensor(\"LabelData:0\", shape=(?, 30), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5nIyYWewdkq"
      },
      "source": [
        "\"\"\"\n",
        "Functions used to define models\n",
        "\"\"\"\n",
        "\n",
        "haptic_skip_2nd_maxpool = [\"grasp\", \"hold\", \"low\"]\n",
        "\n",
        "def model(video_data_placeholder):\n",
        "    with tf.name_scope(\"Model\"):\n",
        "        # Video\n",
        "        net = tf.layers.flatten(video_data_placeholder)\n",
        "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
        "        net = tf.layers.dropout(inputs=net)\n",
        "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
        "        net = tf.layers.dropout(inputs=net)\n",
        "        video_logits = tf.layers.dense(inputs=net, units=num_classes, activation=tf.nn.relu)\n",
        "        \n",
        "        # Audio\n",
        "        audio_data_placeholder = tf.placeholder('float', [None, audio_frames_max, audio_size], name='audio_InputData')\n",
        "        net = tf.layers.flatten(audio_data_placeholder)\n",
        "        # Dense Layer\n",
        "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
        "        net = tf.layers.dropout(inputs=net, rate=audio_keep_prob)\n",
        "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
        "        net = tf.layers.dropout(inputs=net, rate=audio_keep_prob)\n",
        "        audio_logits = tf.layers.dense(inputs=net, units=num_classes, activation=tf.nn.relu)\n",
        "        \n",
        "        # Haptic\n",
        "        haptic_data_placeholder = tf.placeholder('float', [None, haptic_frames_max, haptic_size], name='haptic_InputData')\n",
        "        net = tf.layers.flatten(haptic_data_placeholder)\n",
        "        # Dense Layer\n",
        "        net = tf.layers.dense(inputs=net, units=256, activation=tf.nn.relu)\n",
        "        net = tf.layers.dropout(inputs=net, rate=haptic_keep_prob)\n",
        "        haptic_logits = tf.layers.dense(inputs=net, units=num_classes, activation=tf.nn.relu)\n",
        "        \n",
        "        # Concatenate \n",
        "        logits = tf.concat([video_logits, audio_logits, haptic_logits], axis=1)\n",
        "        logits = tf.nn.relu(logits)\n",
        "        logits = tf.layers.dense(inputs=logits, units=num_classes)\n",
        "        \n",
        "    return logits\n",
        "\n",
        "\n",
        "def loss(prediction, label_placeholder):\n",
        "    with tf.name_scope('Loss'):\n",
        "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=label_placeholder))\n",
        "        # Create a summary to monitor cost tensor\n",
        "        cost_scalar = tf.summary.scalar(\"loss\", cost)\n",
        "    return cost, cost_scalar\n",
        "\n",
        "def training(prediction, label_placeholder):\n",
        "    with tf.name_scope('Optimizer'):\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "        train_op = optimizer.minimize(cost)\n",
        "    return train_op\n",
        "\n",
        "def evaluate(prediction, Y):\n",
        "    with tf.name_scope('Accuracy'):\n",
        "        # Test model\n",
        "        correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "        # Calculate accuracy\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
        "        # Create a summary to monitor accuracy tensor\n",
        "        accuracy_scalar = tf.summary.scalar(\"accuracy\", accuracy)\n",
        "    return accuracy, accuracy_scalar"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9YnsTz-wdkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c05ca52-9988-4619-dc09-465e69ca24bc"
      },
      "source": [
        "\"\"\"\n",
        "Creating the Neural Network\n",
        "\"\"\"\n",
        "\n",
        "model_dict = {}\n",
        "prediction = model(video_X)\n",
        "model_dict[\"Model\"] = prediction\n",
        "\n",
        "cost, cost_scalar = loss(prediction, Y)\n",
        "model_dict[\"Loss\"] = cost\n",
        "model_dict[\"Loss_scalar\"] = cost_scalar\n",
        "\n",
        "train_op = training(prediction, Y)\n",
        "model_dict[\"Optimizer\"] = train_op\n",
        "\n",
        "eval_op, accuracy_scalar = evaluate(prediction, Y)\n",
        "model_dict[\"Accuracy\"] = eval_op\n",
        "model_dict[\"Accuracy_scalar\"] = accuracy_scalar\n",
        "\n",
        "print(\"model_dict: \", model_dict)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 'Saver' op to save and restore all the variables\n",
        "saver = tf.train.Saver(max_to_keep=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-b1b823964818>:10: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-b1b823964818>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-b1b823964818>:12: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "model_dict:  {'Model': <tf.Tensor 'Model/dense_8/BiasAdd:0' shape=(?, 30) dtype=float32>, 'Loss': <tf.Tensor 'Loss/Mean:0' shape=() dtype=float32>, 'Loss_scalar': <tf.Tensor 'Loss/loss:0' shape=() dtype=string>, 'Optimizer': <tf.Operation 'Optimizer/Adam' type=NoOp>, 'Accuracy': <tf.Tensor 'Accuracy/Mean:0' shape=() dtype=float32>, 'Accuracy_scalar': <tf.Tensor 'Accuracy/accuracy:0' shape=() dtype=string>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZj8uywlwdks"
      },
      "source": [
        "if os.path.exists(logs_path):\n",
        "    shutil.rmtree(logs_path)\n",
        "    os.makedirs(logs_path)\n",
        "else:\n",
        "    os.makedirs(logs_path)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EymUeUC2wdks"
      },
      "source": [
        "\"\"\"\n",
        "Writing 'Time', 'Epoch', 'Cost', 'Accuracy' in CSV file\n",
        "\"\"\"\n",
        "\n",
        "epoch_cost_accuracy = []\n",
        "epoch_cost_accuracy.append(\"Time\")\n",
        "epoch_cost_accuracy.append(\"Epoch\")\n",
        "epoch_cost_accuracy.append(\"Cost\")\n",
        "epoch_cost_accuracy.append(\"Accuracy\")\n",
        "\n",
        "with open(logs_path+folder_name+\"_data.csv\",'w') as f:\n",
        "    writer = csv.writer(f, lineterminator=\"\\n\")\n",
        "    writer.writerow(epoch_cost_accuracy)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRcpBIjXwdks"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "O-ghKlW9wdkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7d719b-9394-44e7-a2c6-4d42978e0d91"
      },
      "source": [
        "\"\"\"## Training\"\"\"\n",
        "\n",
        "# Start Training\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Initialize variables\n",
        "    sess.run(init)\n",
        "    \n",
        "    # op to write logs to Tensorboard\n",
        "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "    \n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost_list = 0.0\n",
        "        total_batch = int(len(train_id)/batch)\n",
        "        \n",
        "        # Shuffle data\n",
        "        np.random.shuffle(train_id)\n",
        "        \n",
        "        i = 0\n",
        "        # Loop over all batches\n",
        "        for start, end in zip(range(0, len(train_id), batch), range(batch, len(train_id)+1, batch)):\n",
        "            video_input_data, label_data = video_frames[train_id][start:end], object_label_one_hot[train_id][start:end]\n",
        "\n",
        "            audio_input_data = audio_frames[train_id][start:end]\n",
        "            audio_X = tf.get_default_graph().get_tensor_by_name(\"Model/audio_InputData:0\")\n",
        "\n",
        "            haptic_input_data = haptic_frames[train_id][start:end]\n",
        "            haptic_X = tf.get_default_graph().get_tensor_by_name(\"Model/haptic_InputData:0\")\n",
        "\n",
        "            _, new_cost, cost_scalar = sess.run(\n",
        "                [model_dict[\"Optimizer\"], model_dict[\"Loss\"], model_dict[\"Loss_scalar\"]], \n",
        "                feed_dict={\n",
        "                    video_X: video_input_data, \n",
        "                    audio_X: audio_input_data, \n",
        "                    haptic_X: haptic_input_data, \n",
        "                    Y: label_data, \n",
        "                    audio_keep_prob: 0.5, \n",
        "                    haptic_keep_prob: 0.5\n",
        "                    }\n",
        "                )\n",
        "            # Compute average loss\n",
        "            avg_cost_list += new_cost/total_batch\n",
        "\n",
        "            summary_writer.add_summary(cost_scalar, epoch * total_batch + i)\n",
        "            i += 1\n",
        "        save_path = saver.save(sess, model_path, epoch)\n",
        "         \n",
        "        # Calculate Accuracy\n",
        "        avg_accuracy_list = 0.0\n",
        "        total_batch = int(len(test_id)/batch)\n",
        "        i = 0\n",
        "        for start, end in zip(range(0, len(test_id), batch), range(batch, len(test_id)+1, batch)):\n",
        "            video_input_data, label_data = video_frames[test_id][start:end], object_label_one_hot[test_id][start:end]\n",
        "\n",
        "            audio_input_data = audio_frames[test_id][start:end]\n",
        "            audio_X = tf.get_default_graph().get_tensor_by_name(\"Model/audio_InputData:0\")\n",
        "\n",
        "            haptic_input_data = haptic_frames[test_id][start:end]\n",
        "            haptic_X = tf.get_default_graph().get_tensor_by_name(\"Model/haptic_InputData:0\")\n",
        "\n",
        "            accuracy, accuracy_scalar = sess.run([model_dict[\"Accuracy\"], model_dict[\"Accuracy_scalar\"]], feed_dict={video_X: video_input_data, audio_X: audio_input_data, haptic_X: haptic_input_data, Y: label_data, audio_keep_prob: 1.0, haptic_keep_prob: 1.0})\n",
        "            # Compute average accuracy\n",
        "            avg_accuracy_list += accuracy/total_batch\n",
        "            summary_writer.add_summary(accuracy_scalar, epoch * total_batch + i)\n",
        "            i += 1\n",
        "        \n",
        "        # Printing current epoch accuracy\n",
        "        epoch_cost_accuracy = []\n",
        "        epoch_cost_accuracy.append(time_taken(start_time, time.time()))\n",
        "        # Display logs per epoch step\n",
        "        if epoch % display_step == 0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \", Time: \", time_taken(start_time, time.time()))\n",
        "            a_string = \"Cost - \"\n",
        "            epoch_cost_accuracy.append(epoch+1)\n",
        "            \n",
        "            a_string += str(avg_cost_list)\n",
        "            epoch_cost_accuracy.append(str(avg_cost_list))\n",
        "            \n",
        "            a_string = a_string[0:-2]+\" --> Accuracy - \"\n",
        "            a_string += str(avg_accuracy_list)\n",
        "            epoch_cost_accuracy.append(str(avg_accuracy_list))\n",
        "            \n",
        "            print(a_string)\n",
        "        \n",
        "        # Writing current epoch data\n",
        "        with open(logs_path+folder_name+\"_data.csv\", 'a') as f: # append to the file created\n",
        "            writer = csv.writer(f, lineterminator=\"\\n\")\n",
        "            writer.writerow(epoch_cost_accuracy)\n",
        "    \n",
        "    print(\"Optimization Finished!\")\n",
        "    end_time = time.time()\n",
        "    print(\"Time taken: day, hour, minutes, seconds->\", time_taken(start_time, end_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 , Time:  00:00:00:02\n",
            "Cost - 4.6383654541439 --> Accuracy - 0.06666666766007741\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Epoch: 0002 , Time:  00:00:00:04\n",
            "Cost - 3.0152998434172 --> Accuracy - 0.033333333830038704\n",
            "Epoch: 0003 , Time:  00:00:00:07\n",
            "Cost - 2.6057001815901 --> Accuracy - 0.11666666840513545\n",
            "Epoch: 0004 , Time:  00:00:00:09\n",
            "Cost - 2.20577307873302 --> Accuracy - 0.05000000074505806\n",
            "Epoch: 0005 , Time:  00:00:00:11\n",
            "Cost - 1.87678513758712 --> Accuracy - 0.08333333457509676\n",
            "Epoch: 0006 , Time:  00:00:00:13\n",
            "Cost - 1.59312169916099 --> Accuracy - 0.1000000014901161\n",
            "Epoch: 0007 , Time:  00:00:00:15\n",
            "Cost - 1.34687074025472 --> Accuracy - 0.11666666840513545\n",
            "Epoch: 0008 , Time:  00:00:00:17\n",
            "Cost - 1.10875417292118 --> Accuracy - 0.18333333606521288\n",
            "Epoch: 0009 , Time:  00:00:00:19\n",
            "Cost - 0.81529446939627 --> Accuracy - 0.15000000223517418\n",
            "Epoch: 0010 , Time:  00:00:00:21\n",
            "Cost - 0.62299941480159 --> Accuracy - 0.1833333360652129\n",
            "Epoch: 0011 , Time:  00:00:00:23\n",
            "Cost - 0.48256533303194 --> Accuracy - 0.1833333360652129\n",
            "Epoch: 0012 , Time:  00:00:00:25\n",
            "Cost - 0.356999643767873 --> Accuracy - 0.16666666915019354\n",
            "Epoch: 0013 , Time:  00:00:00:28\n",
            "Cost - 0.25949313336362 --> Accuracy - 0.21666667113701502\n",
            "Epoch: 0014 , Time:  00:00:00:30\n",
            "Cost - 0.16746136235694 --> Accuracy - 0.2333333380520344\n",
            "Epoch: 0015 , Time:  00:00:00:32\n",
            "Cost - 0.14647562393090 --> Accuracy - 0.2500000049670537\n",
            "Epoch: 0016 , Time:  00:00:00:34\n",
            "Cost - 0.120848258207034 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0017 , Time:  00:00:00:36\n",
            "Cost - 0.08033618589656 --> Accuracy - 0.28333334003885585\n",
            "Epoch: 0018 , Time:  00:00:00:38\n",
            "Cost - 0.0590154922101646 --> Accuracy - 0.23333333681027094\n",
            "Epoch: 0019 , Time:  00:00:00:40\n",
            "Cost - 0.044021875519926 --> Accuracy - 0.28333334003885585\n",
            "Epoch: 0020 , Time:  00:00:00:42\n",
            "Cost - 0.0334778734120643 --> Accuracy - 0.2500000037252903\n",
            "Epoch: 0021 , Time:  00:00:00:45\n",
            "Cost - 0.0289626290193862 --> Accuracy - 0.25000000372529024\n",
            "Epoch: 0022 , Time:  00:00:00:47\n",
            "Cost - 0.024943715504681 --> Accuracy - 0.2500000037252903\n",
            "Epoch: 0023 , Time:  00:00:00:49\n",
            "Cost - 0.021662085135984 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0024 , Time:  00:00:00:51\n",
            "Cost - 0.0194738404825329 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0025 , Time:  00:00:00:54\n",
            "Cost - 0.0172113118072350 --> Accuracy - 0.21666666989525157\n",
            "Epoch: 0026 , Time:  00:00:00:56\n",
            "Cost - 0.0157470442290003 --> Accuracy - 0.2500000049670537\n",
            "Epoch: 0027 , Time:  00:00:00:58\n",
            "Cost - 0.0141038293044807 --> Accuracy - 0.2500000049670537\n",
            "Epoch: 0028 , Time:  00:00:01:00\n",
            "Cost - 0.0131167350983661 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0029 , Time:  00:00:01:02\n",
            "Cost - 0.012119874901448 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0030 , Time:  00:00:01:04\n",
            "Cost - 0.0112146970608996 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0031 , Time:  00:00:01:07\n",
            "Cost - 0.0103796933932850 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0032 , Time:  00:00:01:09\n",
            "Cost - 0.0095128721182441 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0033 , Time:  00:00:01:11\n",
            "Cost - 0.0089073602705159 --> Accuracy - 0.26666667188207305\n",
            "Epoch: 0034 , Time:  00:00:01:13\n",
            "Cost - 0.0082539093046863 --> Accuracy - 0.23333333805203438\n",
            "Epoch: 0035 , Time:  00:00:01:15\n",
            "Cost - 0.0076673110921142 --> Accuracy - 0.2500000049670537\n",
            "Epoch: 0036 , Time:  00:00:01:17\n",
            "Cost - 0.0072577265608641 --> Accuracy - 0.2500000049670537\n",
            "Epoch: 0037 , Time:  00:00:01:19\n",
            "Cost - 0.0067647108743484 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0038 , Time:  00:00:01:22\n",
            "Cost - 0.006339393562585 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0039 , Time:  00:00:01:24\n",
            "Cost - 0.0059471836882746 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0040 , Time:  00:00:01:26\n",
            "Cost - 0.00567752845624151 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0041 , Time:  00:00:01:28\n",
            "Cost - 0.0052929393132217 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0042 , Time:  00:00:01:30\n",
            "Cost - 0.0050125140793776 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0043 , Time:  00:00:01:32\n",
            "Cost - 0.0047525982663501 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0044 , Time:  00:00:01:34\n",
            "Cost - 0.0045113056516533 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0045 , Time:  00:00:01:37\n",
            "Cost - 0.0042920734558720 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0046 , Time:  00:00:01:39\n",
            "Cost - 0.0041030961858470 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0047 , Time:  00:00:01:41\n",
            "Cost - 0.00389917280861 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0048 , Time:  00:00:01:43\n",
            "Cost - 0.0036935682809497 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0049 , Time:  00:00:01:45\n",
            "Cost - 0.00351373531157150 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0050 , Time:  00:00:01:47\n",
            "Cost - 0.0033537880485204 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0051 , Time:  00:00:01:49\n",
            "Cost - 0.00317701341312689 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0052 , Time:  00:00:01:51\n",
            "Cost - 0.0030383789885996 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0053 , Time:  00:00:01:53\n",
            "Cost - 0.00292421809151872 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0054 , Time:  00:00:01:56\n",
            "Cost - 0.0027661510151422 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0055 , Time:  00:00:01:58\n",
            "Cost - 0.0026408447366621 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0056 , Time:  00:00:02:00\n",
            "Cost - 0.0025491663933886 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0057 , Time:  00:00:02:02\n",
            "Cost - 0.00244697733109609 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0058 , Time:  00:00:02:04\n",
            "Cost - 0.00235616558509516 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0059 , Time:  00:00:02:06\n",
            "Cost - 0.00224346520715496 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0060 , Time:  00:00:02:08\n",
            "Cost - 0.0021680079064228 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0061 , Time:  00:00:02:10\n",
            "Cost - 0.00207554792480853 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0062 , Time:  00:00:02:13\n",
            "Cost - 0.00198713009982990 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0063 , Time:  00:00:02:15\n",
            "Cost - 0.00191138578358934 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0064 , Time:  00:00:02:17\n",
            "Cost - 0.00184900337707303 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0065 , Time:  00:00:02:19\n",
            "Cost - 0.00177672248618263 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0066 , Time:  00:00:02:21\n",
            "Cost - 0.00171508808529728 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0067 , Time:  00:00:02:23\n",
            "Cost - 0.00165527561168548 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0068 , Time:  00:00:02:25\n",
            "Cost - 0.0015941714777404 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0069 , Time:  00:00:02:27\n",
            "Cost - 0.00155593375610705 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0070 , Time:  00:00:02:29\n",
            "Cost - 0.00148654417070146 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0071 , Time:  00:00:02:31\n",
            "Cost - 0.0014401734547896 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0072 , Time:  00:00:02:35\n",
            "Cost - 0.0013894330687536 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0073 , Time:  00:00:02:37\n",
            "Cost - 0.00135054905290922 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0074 , Time:  00:00:02:39\n",
            "Cost - 0.00130279636424448 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0075 , Time:  00:00:02:41\n",
            "Cost - 0.00126157604245236 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0076 , Time:  00:00:02:43\n",
            "Cost - 0.00121877541662090 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0077 , Time:  00:00:02:46\n",
            "Cost - 0.00118911002937238 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0078 , Time:  00:00:02:48\n",
            "Cost - 0.00115223148249141 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0079 , Time:  00:00:02:50\n",
            "Cost - 0.0011186866953115 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0080 , Time:  00:00:02:52\n",
            "Cost - 0.00107637387312327 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0081 , Time:  00:00:02:54\n",
            "Cost - 0.00104739192627473 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0082 , Time:  00:00:02:57\n",
            "Cost - 0.0010171938629355 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0083 , Time:  00:00:03:00\n",
            "Cost - 0.00098278997837850 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0084 , Time:  00:00:03:02\n",
            "Cost - 0.00095909251184720 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0085 , Time:  00:00:03:04\n",
            "Cost - 0.00092838420823682 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0086 , Time:  00:00:03:06\n",
            "Cost - 0.0009041050604234 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0087 , Time:  00:00:03:09\n",
            "Cost - 0.00087752916927759 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0088 , Time:  00:00:03:11\n",
            "Cost - 0.00085127686826227 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0089 , Time:  00:00:03:13\n",
            "Cost - 0.00082740390805863 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0090 , Time:  00:00:03:15\n",
            "Cost - 0.00080529715584513 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0091 , Time:  00:00:03:17\n",
            "Cost - 0.00078199257728152 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0092 , Time:  00:00:03:19\n",
            "Cost - 0.00076096257220746 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0093 , Time:  00:00:03:22\n",
            "Cost - 0.000742434313805 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0094 , Time:  00:00:03:25\n",
            "Cost - 0.00071889513654039 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0095 , Time:  00:00:03:27\n",
            "Cost - 0.00070142678830759 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0096 , Time:  00:00:03:29\n",
            "Cost - 0.00068203379568229 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0097 , Time:  00:00:03:32\n",
            "Cost - 0.00066357292719961 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0098 , Time:  00:00:03:35\n",
            "Cost - 0.00064378355940182 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0099 , Time:  00:00:03:37\n",
            "Cost - 0.00062813027195968 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0100 , Time:  00:00:03:39\n",
            "Cost - 0.0006123546303974 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0101 , Time:  00:00:03:41\n",
            "Cost - 0.00059655372347656 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0102 , Time:  00:00:03:43\n",
            "Cost - 0.00058224934441063 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0103 , Time:  00:00:03:45\n",
            "Cost - 0.00056864876953315 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0104 , Time:  00:00:03:47\n",
            "Cost - 0.00055102322059812 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0105 , Time:  00:00:03:51\n",
            "Cost - 0.00053734253338512 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0106 , Time:  00:00:03:53\n",
            "Cost - 0.00052466294841401 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0107 , Time:  00:00:03:55\n",
            "Cost - 0.00051049037170337 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0108 , Time:  00:00:03:58\n",
            "Cost - 0.00049954954415119 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0109 , Time:  00:00:04:00\n",
            "Cost - 0.000485391468019871 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0110 , Time:  00:00:04:02\n",
            "Cost - 0.000472145672473642 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0111 , Time:  00:00:04:04\n",
            "Cost - 0.000461615983011951 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0112 , Time:  00:00:04:06\n",
            "Cost - 0.000448902819092230 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0113 , Time:  00:00:04:09\n",
            "Cost - 0.00043822514958770 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0114 , Time:  00:00:04:11\n",
            "Cost - 0.000427625739879052 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0115 , Time:  00:00:04:13\n",
            "Cost - 0.000416301151643791 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0116 , Time:  00:00:04:16\n",
            "Cost - 0.000409212686564488 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0117 , Time:  00:00:04:18\n",
            "Cost - 0.0003958828811947 --> Accuracy - 0.21666667113701502\n",
            "Epoch: 0118 , Time:  00:00:04:21\n",
            "Cost - 0.000387198386306408 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0119 , Time:  00:00:04:23\n",
            "Cost - 0.000378648727847677 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0120 , Time:  00:00:04:25\n",
            "Cost - 0.000370538232447062 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0121 , Time:  00:00:04:27\n",
            "Cost - 0.000360527599291850 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0122 , Time:  00:00:04:29\n",
            "Cost - 0.00035240725426572 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0123 , Time:  00:00:04:32\n",
            "Cost - 0.0003434451096432 --> Accuracy - 0.21666667113701502\n",
            "Epoch: 0124 , Time:  00:00:04:35\n",
            "Cost - 0.00033520335515883 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0125 , Time:  00:00:04:37\n",
            "Cost - 0.000327056035328294 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0126 , Time:  00:00:04:39\n",
            "Cost - 0.000318894089610289 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0127 , Time:  00:00:04:41\n",
            "Cost - 0.00031206338220120 --> Accuracy - 0.23333333805203435\n",
            "Epoch: 0128 , Time:  00:00:04:43\n",
            "Cost - 0.000306338121542163 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0129 , Time:  00:00:04:46\n",
            "Cost - 0.00029787607248484 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0130 , Time:  00:00:04:48\n",
            "Cost - 0.000291676470725279 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0131 , Time:  00:00:04:51\n",
            "Cost - 0.00028424253428561 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0132 , Time:  00:00:04:53\n",
            "Cost - 0.000277653726192915 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0133 , Time:  00:00:04:55\n",
            "Cost - 0.00027201122490320 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0134 , Time:  00:00:04:57\n",
            "Cost - 0.000266308329325208 --> Accuracy - 0.2500000062088171\n",
            "Epoch: 0135 , Time:  00:00:04:59\n",
            "Cost - 0.00025957642436777 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0136 , Time:  00:00:05:01\n",
            "Cost - 0.00025346505612510 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0137 , Time:  00:00:05:05\n",
            "Cost - 0.000247973810878142 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0138 , Time:  00:00:05:07\n",
            "Cost - 0.00024238121012684 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0139 , Time:  00:00:05:09\n",
            "Cost - 0.00023611424694536 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0140 , Time:  00:00:05:11\n",
            "Cost - 0.000231189464304609 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0141 , Time:  00:00:05:14\n",
            "Cost - 0.000225796544125639 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0142 , Time:  00:00:05:16\n",
            "Cost - 0.000221199903939527 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0143 , Time:  00:00:05:19\n",
            "Cost - 0.000215307183882234 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0144 , Time:  00:00:05:21\n",
            "Cost - 0.00021106274895525 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0145 , Time:  00:00:05:23\n",
            "Cost - 0.000206595970666967 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0146 , Time:  00:00:05:25\n",
            "Cost - 0.000201987092724367 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0147 , Time:  00:00:05:27\n",
            "Cost - 0.00019697743401694 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0148 , Time:  00:00:05:29\n",
            "Cost - 0.000192662411387168 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0149 , Time:  00:00:05:33\n",
            "Cost - 0.00018847225793352 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0150 , Time:  00:00:05:35\n",
            "Cost - 0.000184473883766461 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0151 , Time:  00:00:05:37\n",
            "Cost - 0.000180107943176860 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0152 , Time:  00:00:05:40\n",
            "Cost - 0.000176466704134428 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0153 , Time:  00:00:05:42\n",
            "Cost - 0.00017259442251492 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0154 , Time:  00:00:05:44\n",
            "Cost - 0.000168863076800739 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0155 , Time:  00:00:05:46\n",
            "Cost - 0.000165055403461641 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0156 , Time:  00:00:05:48\n",
            "Cost - 0.000161058104216256 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0157 , Time:  00:00:05:51\n",
            "Cost - 0.000157577169375144 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0158 , Time:  00:00:05:54\n",
            "Cost - 0.00015427004331690 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0159 , Time:  00:00:05:56\n",
            "Cost - 0.000151133341609642 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0160 , Time:  00:00:05:58\n",
            "Cost - 0.00014789201991839 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0161 , Time:  00:00:06:01\n",
            "Cost - 0.0001448729314385 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0162 , Time:  00:00:06:03\n",
            "Cost - 0.000141439897359103 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0163 , Time:  00:00:06:05\n",
            "Cost - 0.00013848805388584 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0164 , Time:  00:00:06:07\n",
            "Cost - 0.00013571527759065 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0165 , Time:  00:00:06:09\n",
            "Cost - 0.000132067010680556 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0166 , Time:  00:00:06:12\n",
            "Cost - 0.000129515143574584 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0167 , Time:  00:00:06:14\n",
            "Cost - 0.000126391910978 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0168 , Time:  00:00:06:16\n",
            "Cost - 0.000124078558150762 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0169 , Time:  00:00:06:19\n",
            "Cost - 0.000120953955754682 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0170 , Time:  00:00:06:21\n",
            "Cost - 0.000118527921383954 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0171 , Time:  00:00:06:23\n",
            "Cost - 0.000115406615704058 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0172 , Time:  00:00:06:25\n",
            "Cost - 0.000112891851434445 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0173 , Time:  00:00:06:29\n",
            "Cost - 0.000110769500578397 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0174 , Time:  00:00:06:31\n",
            "Cost - 0.000108353522793752 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0175 , Time:  00:00:06:33\n",
            "Cost - 0.000105536082426422 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0176 , Time:  00:00:06:35\n",
            "Cost - 0.00010313976943305 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0177 , Time:  00:00:06:37\n",
            "Cost - 0.000100855374310210 --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0178 , Time:  00:00:06:40\n",
            "Cost - 9.841332868947777e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0179 , Time:  00:00:06:42\n",
            "Cost - 9.632682849769485e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0180 , Time:  00:00:06:44\n",
            "Cost - 9.452644685047239e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0181 , Time:  00:00:06:46\n",
            "Cost - 9.217505198143447e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0182 , Time:  00:00:06:48\n",
            "Cost - 8.998595462293855e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0183 , Time:  00:00:06:50\n",
            "Cost - 8.827957137529869e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0184 , Time:  00:00:06:52\n",
            "Cost - 8.632548805407067e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0185 , Time:  00:00:06:55\n",
            "Cost - 8.438000865377641e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0186 , Time:  00:00:06:58\n",
            "Cost - 8.254507065430514e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0187 , Time:  00:00:07:00\n",
            "Cost - 8.087444929414132e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0188 , Time:  00:00:07:02\n",
            "Cost - 7.906139914363543e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0189 , Time:  00:00:07:06\n",
            "Cost - 7.745156573138147e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0190 , Time:  00:00:07:08\n",
            "Cost - 7.581736160015379e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0191 , Time:  00:00:07:10\n",
            "Cost - 7.429239425012689e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0192 , Time:  00:00:07:12\n",
            "Cost - 7.266071426986146e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0193 , Time:  00:00:07:14\n",
            "Cost - 7.102045057965572e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0194 , Time:  00:00:07:16\n",
            "Cost - 6.961067214837788e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0195 , Time:  00:00:07:19\n",
            "Cost - 6.846507706844325e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0196 , Time:  00:00:07:21\n",
            "Cost - 6.677712705519903e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0197 , Time:  00:00:07:23\n",
            "Cost - 6.524350252827087e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0198 , Time:  00:00:07:25\n",
            "Cost - 6.374493376723776e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0199 , Time:  00:00:07:27\n",
            "Cost - 6.255696578389486e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0200 , Time:  00:00:07:30\n",
            "Cost - 6.098157640129405e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0201 , Time:  00:00:07:33\n",
            "Cost - 6.005310286935936e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0202 , Time:  00:00:07:35\n",
            "Cost - 5.8720143897517125e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0203 , Time:  00:00:07:37\n",
            "Cost - 5.737650624521646e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0204 , Time:  00:00:07:39\n",
            "Cost - 5.620773193489489e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0205 , Time:  00:00:07:41\n",
            "Cost - 5.504489025851298e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0206 , Time:  00:00:07:44\n",
            "Cost - 5.3567505043853686e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0207 , Time:  00:00:07:46\n",
            "Cost - 5.2665563645051495e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0208 , Time:  00:00:07:49\n",
            "Cost - 5.141663561719018e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0209 , Time:  00:00:07:51\n",
            "Cost - 5.0696119413057896e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0210 , Time:  00:00:07:53\n",
            "Cost - 4.929026135869209e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0211 , Time:  00:00:07:55\n",
            "Cost - 4.837374591362378e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0212 , Time:  00:00:07:57\n",
            "Cost - 4.736187161648154e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0213 , Time:  00:00:08:00\n",
            "Cost - 4.633080233260342e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0214 , Time:  00:00:08:02\n",
            "Cost - 4.529641834475721e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0215 , Time:  00:00:08:04\n",
            "Cost - 4.443750483713098e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0216 , Time:  00:00:08:06\n",
            "Cost - 4.3384576656535494e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0217 , Time:  00:00:08:08\n",
            "Cost - 4.236143574113763e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0218 , Time:  00:00:08:11\n",
            "Cost - 4.166476633650341e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0219 , Time:  00:00:08:14\n",
            "Cost - 4.068600588248551e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0220 , Time:  00:00:08:16\n",
            "Cost - 3.992776335811261e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0221 , Time:  00:00:08:18\n",
            "Cost - 3.898673356969892e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0222 , Time:  00:00:08:20\n",
            "Cost - 3.808279673952105e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0223 , Time:  00:00:08:22\n",
            "Cost - 3.732782432861213e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0224 , Time:  00:00:08:24\n",
            "Cost - 3.661660755622304e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0225 , Time:  00:00:08:26\n",
            "Cost - 3.5719955879661314e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0226 , Time:  00:00:08:28\n",
            "Cost - 3.5008046628111814e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0227 , Time:  00:00:08:31\n",
            "Cost - 3.4282902687563256e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0228 , Time:  00:00:08:34\n",
            "Cost - 3.350476774560068e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0229 , Time:  00:00:08:37\n",
            "Cost - 3.282134967877129e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0230 , Time:  00:00:08:39\n",
            "Cost - 3.219487502469241e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0231 , Time:  00:00:08:41\n",
            "Cost - 3.150548718622303e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0232 , Time:  00:00:08:43\n",
            "Cost - 3.076575649174629e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0233 , Time:  00:00:08:45\n",
            "Cost - 3.0263784942184837e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0234 , Time:  00:00:08:47\n",
            "Cost - 2.953532591871206e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0235 , Time:  00:00:08:51\n",
            "Cost - 2.8890966480806433e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0236 , Time:  00:00:08:53\n",
            "Cost - 2.8367798121406744e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0237 , Time:  00:00:08:55\n",
            "Cost - 2.783667082439933e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0238 , Time:  00:00:08:57\n",
            "Cost - 2.7220789762496774e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0239 , Time:  00:00:08:59\n",
            "Cost - 2.6555232504203254e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0240 , Time:  00:00:09:01\n",
            "Cost - 2.6016833215989107e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0241 , Time:  00:00:09:05\n",
            "Cost - 2.546187359560766e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0242 , Time:  00:00:09:07\n",
            "Cost - 2.4947965989162592e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0243 , Time:  00:00:09:10\n",
            "Cost - 2.44671781880849e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0244 , Time:  00:00:09:12\n",
            "Cost - 2.389235348548229e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0245 , Time:  00:00:09:14\n",
            "Cost - 2.333341252678009e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0246 , Time:  00:00:09:16\n",
            "Cost - 2.2876462000769807e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0247 , Time:  00:00:09:18\n",
            "Cost - 2.24095816873968e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0248 , Time:  00:00:09:20\n",
            "Cost - 2.1965875197969988e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0249 , Time:  00:00:09:22\n",
            "Cost - 2.1498323601715838e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0250 , Time:  00:00:09:26\n",
            "Cost - 2.1034090145298655e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0251 , Time:  00:00:09:28\n",
            "Cost - 2.0567863265973254e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0252 , Time:  00:00:09:30\n",
            "Cost - 2.0195680766240308e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0253 , Time:  00:00:09:32\n",
            "Cost - 1.9733427507162563e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0254 , Time:  00:00:09:34\n",
            "Cost - 1.9289716798690886e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0255 , Time:  00:00:09:36\n",
            "Cost - 1.890230585862203e- --> Accuracy - 0.23333333929379782\n",
            "Epoch: 0256 , Time:  00:00:09:38\n",
            "Cost - 1.848375955483385e- --> Accuracy - 0.23333333929379782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qxjz02zwdku"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}